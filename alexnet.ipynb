{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AlexNet Module** "
      ],
      "metadata": {
        "id": "6L1Qx6ILzhmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E3OY6rILIgF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3TU4_cRLIgK"
      },
      "outputs": [],
      "source": [
        "# np.load(path, allow_pickle=True)\n",
        "net_data = np.load(\"bvlc-alexnet.npy\",allow_pickle=True, encoding=\"latin1\").item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvMPH06_LIgK"
      },
      "outputs": [],
      "source": [
        "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
        "    '''\n",
        "    From https://github.com/ethereon/caffe-tensorflow\n",
        "    '''\n",
        "    c_i = input.get_shape()[-1]\n",
        "    assert c_i % group == 0\n",
        "    assert c_o % group == 0\n",
        "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
        "    if tf.__version__ < \"1.0.0\":\n",
        "        if group == 1:\n",
        "            conv = convolve(input, kernel)\n",
        "        else:\n",
        "            input_groups = tf.split(3, group, input)\n",
        "            kernel_groups = tf.split(3, group, kernel)\n",
        "            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
        "            conv = tf.concat(3, output_groups)\n",
        "    else:\n",
        "        if group == 1:\n",
        "            conv = convolve(input, kernel)\n",
        "        else:\n",
        "            input_groups = tf.split(input, group, 3)\n",
        "            kernel_groups = tf.split(kernel, group, 3)\n",
        "            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
        "            conv = tf.concat(output_groups, 3)\n",
        "    return tf.reshape(tf.nn.bias_add(conv, biases), [-1] + conv.get_shape().as_list()[1:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet(features, feature_extract=False):\n",
        "    \"\"\"\n",
        "    Builds an AlexNet model, loads pretrained weights\n",
        "    \"\"\"\n",
        "    # conv1\n",
        "    # conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
        "    k_h = 11\n",
        "    k_w = 11\n",
        "    c_o = 96\n",
        "    s_h = 4\n",
        "    s_w = 4\n",
        "    conv1W = tf.Variable(net_data[\"conv1\"][0])\n",
        "    conv1b = tf.Variable(net_data[\"conv1\"][1])\n",
        "    conv1_in = conv(features, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
        "    conv1 = tf.nn.relu(conv1_in)\n",
        "\n",
        "    # lrn1\n",
        "    # lrn(2, 2e-05, 0.75, name='norm1')\n",
        "    radius = 2\n",
        "    alpha = 2e-05\n",
        "    beta = 0.75\n",
        "    bias = 1.0\n",
        "    lrn1 = tf.nn.local_response_normalization(conv1, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
        "\n",
        "    # maxpool1\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # conv2\n",
        "    # conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
        "    k_h = 5\n",
        "    k_w = 5\n",
        "    c_o = 256\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv2W = tf.Variable(net_data[\"conv2\"][0])\n",
        "    conv2b = tf.Variable(net_data[\"conv2\"][1])\n",
        "    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv2 = tf.nn.relu(conv2_in)\n",
        "\n",
        "    # lrn2\n",
        "    # lrn(2, 2e-05, 0.75, name='norm2')\n",
        "    radius = 2\n",
        "    alpha = 2e-05\n",
        "    beta = 0.75\n",
        "    bias = 1.0\n",
        "    lrn2 = tf.nn.local_response_normalization(conv2, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
        "\n",
        "    # maxpool2\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # conv3\n",
        "    # conv(3, 3, 384, 1, 1, name='conv3')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 384\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 1\n",
        "    conv3W = tf.Variable(net_data[\"conv3\"][0])\n",
        "    conv3b = tf.Variable(net_data[\"conv3\"][1])\n",
        "    conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv3 = tf.nn.relu(conv3_in)\n",
        "\n",
        "    # conv4\n",
        "    # conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 384\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv4W = tf.Variable(net_data[\"conv4\"][0])\n",
        "    conv4b = tf.Variable(net_data[\"conv4\"][1])\n",
        "    conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv4 = tf.nn.relu(conv4_in)\n",
        "\n",
        "    # conv5\n",
        "    # conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 256\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv5W = tf.Variable(net_data[\"conv5\"][0])\n",
        "    conv5b = tf.Variable(net_data[\"conv5\"][1])\n",
        "    conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv5 = tf.nn.relu(conv5_in)\n",
        "\n",
        "    # maxpool5\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # fc6, 4096\n",
        "    fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
        "    fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
        "    flat5 = tf.reshape(maxpool5, [-1, int(np.prod(maxpool5.get_shape()[1:]))])\n",
        "    fc6 = tf.nn.relu(tf.matmul(flat5, fc6W) + fc6b)\n",
        "\n",
        "    # fc7, 4096\n",
        "    fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
        "    fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
        "    fc7 = tf.nn.relu(tf.matmul(fc6, fc7W) + fc7b)\n",
        "\n",
        "    if feature_extract:\n",
        "        return fc7\n",
        "\n",
        "    '''\n",
        "    we use this layer when  AlexNet  trained on the ImageNet database, \n",
        "    which has 1000 classes of images\n",
        "    '''\n",
        "    # fc8, 1000 \n",
        "    fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
        "    fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
        "\n",
        "    logits = tf.matmul(fc7, fc8W) + fc8b\n",
        "    probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "-HUSHH8dNb-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imagenet_Inference**"
      ],
      "metadata": {
        "id": "b2BwInnmiu25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imread\n",
        "# from caffe_classes import class_names"
      ],
      "metadata": {
        "id": "SS3CL0mTi03d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# x is a placeholders for a batch of input images.\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 227, 227, 3))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h7W2DDRejVWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c6ed384-a888-400c-c97b-c95caa5835ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# x is a placeholders for a batch of input images.\\nx = tf.compat.v1.placeholder(tf.float32, (None, 227, 227, 3))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "probs = AlexNet(x, feature_extract=False)\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# Read Images\n",
        "im1 = (imread(\"poodle.png\")[:, :, :3] * 255).astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = (imread(\"weasel.png\")[:, :, :3] * 255).astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "f__BxLnZjc0K",
        "outputId": "8552db68-c88d-4a60-8b09-9ffd7cd745dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nprobs = AlexNet(x, feature_extract=False)\\ninit = tf.compat.v1.global_variables_initializer()\\nsess = tf.compat.v1.Session()\\nsess.run(init)\\n\\n# Read Images\\nim1 = (imread(\"poodle.png\")[:, :, :3] * 255).astype(np.float32)\\nim1 = im1 - np.mean(im1)\\n\\nim2 = (imread(\"weasel.png\")[:, :, :3] * 255).astype(np.float32)\\nim2 = im2 - np.mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(probs, feed_dict={x: [im1, im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = np.argsort(output)[input_im_ind, :]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time() - t))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Traffic_Sign_Inference**"
      ],
      "metadata": {
        "id": "hpXm2mARnA3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from imageio import imread\n",
        "# from caffe_classes import class_names"
      ],
      "metadata": {
        "id": "QXPa7vfPnCmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# x is a placeholders for a batch of input images.\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "#  resize the chape of the image to (227,227)\n",
        "resized = tf.image.resize(x,(227,227))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8US_OKawnTBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a60c395a-6c1a-4031-c0ee-b2532a91e980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# x is a placeholders for a batch of input images.\\nx = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\\n#  resize the chape of the image to (227,227)\\nresized = tf.image.resize(x,(227,227))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "probs = AlexNet(resized,feature_extract=False)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# Read Images\n",
        "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "R5SAv79up08i",
        "outputId": "373e4c35-e416-4e78-c5a6-5c179ca30e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nprobs = AlexNet(resized,feature_extract=False)\\n\\ninit = tf.compat.v1.global_variables_initializer()\\nsess = tf.compat.v1.Session()\\nsess.run(init)\\n\\n# Read Images\\nim1 = imread(\"construction.jpg\").astype(np.float32)\\nim1 = im1 - np.mean(im1)\\n\\nim2 = imread(\"stop.jpg\").astype(np.float32)\\nim2 = im2 - np.mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(probs, feed_dict={x: [im1, im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = np.argsort(output)[input_im_ind, :]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time() - t))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature_Extraction**"
      ],
      "metadata": {
        "id": "axwvciUubBMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio"
      ],
      "metadata": {
        "id": "fY3MRXlAcgtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbf3759-ca64-4db8-bd3b-338d5d6116ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imageio import imread\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n"
      ],
      "metadata": {
        "id": "7w3RDFKLa7fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "#Load the signname csv file\n",
        "sign_names = pd.read_csv('signnames.csv')\n",
        "nb_classes = 43\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jfMOgd_ucmpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ec20dfe-abbb-44da-cc6d-df4bce755a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n#Load the signname csv file\\nsign_names = pd.read_csv('signnames.csv')\\nnb_classes = 43\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x is a placeholder for a batch of input images."
      ],
      "metadata": {
        "id": "aXAO8ZZieKyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "resized = tf.compat.v1.image.resize_images(x, (227, 227))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WKmzC9xtc0A5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5df1beef-346b-4b24-a4a9-9f02a42a5e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nx = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\\nresized = tf.compat.v1.image.resize_images(x, (227, 227))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# NOTE: By setting `feature_extract` to `True` we return\n",
        "# the second to last layer.\n",
        "fc7 = AlexNet(resized, feature_extract=True)\n",
        "# Last fully connected layer\n",
        "shape = (fc7.get_shape().as_list()[-1], nb_classes)  \n",
        "fc8W = tf.Variable(tf.compat.v1.truncated_normal(shape=shape,  stddev = 1e-1))\n",
        "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
        "logits = tf.matmul(fc7, fc8W) + fc8b\n",
        "# softmax activation function\n",
        "probs = tf.nn.softmax(logits)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vTfeUol3c-Cl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c436ea2a-4f46-4cad-d934-ca355af0b882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# NOTE: By setting `feature_extract` to `True` we return\\n# the second to last layer.\\nfc7 = AlexNet(resized, feature_extract=True)\\n# Last fully connected layer\\nshape = (fc7.get_shape().as_list()[-1], nb_classes)  \\nfc8W = tf.Variable(tf.compat.v1.truncated_normal(shape=shape,  stddev = 1e-1))\\nfc8b = tf.Variable(tf.zeros(nb_classes))\\nlogits = tf.matmul(fc7, fc8W) + fc8b\\n# softmax activation function\\nprobs = tf.nn.softmax(logits)\\n\\ninit = tf.compat.v1.global_variables_initializer()\\nsess = tf.compat.v1.Session()\\nsess.run(init)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# Read Images\n",
        "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (sign_names.loc[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vWBKuCO7dkhI",
        "outputId": "d52deee1-07c8-4da3-8020-7c8c9812b55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Read Images\\nim1 = imread(\"construction.jpg\").astype(np.float32)\\nim1 = im1 - np.mean(im1)\\n\\nim2 = imread(\"stop.jpg\").astype(np.float32)\\nim2 = im2 - np.mean(im2)\\n\\n# Run Inference\\nt = time.time()\\noutput = sess.run(probs, feed_dict={x: [im1, im2]})\\n\\n# Print Output\\nfor input_im_ind in range(output.shape[0]):\\n    inds = np.argsort(output)[input_im_ind, :]\\n    print(\"Image\", input_im_ind)\\n    for i in range(5):\\n        print(\"%s: %.3f\" % (sign_names.loc[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\\n    print()\\n\\nprint(\"Time: %.3f seconds\" % (time.time() - t))\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train_Feature_Extraction**"
      ],
      "metadata": {
        "id": "61lc_3dYyOhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "0Hz5t1kpyQ2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load traffic signs data.\n",
        "training_File = \"train.p\"\n",
        "\n",
        "with open(training_File, mode='rb') as f:\n",
        "    train = pickle.load(f)\n",
        "\n",
        "# Split data into training and validation sets.\n",
        "X_train, X_valid,y_train,y_valid = train_test_split(train['features'], train['labels'],test_size=0.2, random_state=0)\n",
        "\n",
        "# Define placeholders and resize operation.\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "labels = tf.compat.v1.placeholder(tf.int64, None)\n",
        "resized = tf.compat.v1.image.resize_images(x, (227, 227))\n",
        "\n",
        "fc7 = AlexNet(resized, feature_extract=True)\n",
        "# `tf.stop_gradient` prevents the gradient from flowing backwards\n",
        "# past this point, keeping the weights before and up to `fc7` frozen.\n",
        "# This also makes training faster, less work to do!\n",
        "fc7 = tf.stop_gradient(fc7)\n",
        "\n",
        "# the final layer for traffic sign classification.\n",
        "nb_classes = 43\n",
        "shape = (fc7.get_shape().as_list()[-1], nb_classes)  \n",
        "fc8W = tf.Variable(tf.compat.v1.truncated_normal(shape=shape,  stddev = 1e-2))\n",
        "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
        "logits = tf.matmul(fc7, fc8W) + fc8b\n",
        "\n",
        "\n",
        "# Define loss, training, accuracy operations.\n",
        "\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits( logits=logits, labels=labels)\n",
        "loss_operation = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
        "training_operation = optimizer.minimize(loss_operation,var_list=[fc8W,fc8b])\n",
        "init_op = tf.compat.v1.initialize_all_variables()\n",
        "\n",
        "\n",
        "predict_operation = tf.argmax(logits, 1)\n",
        "correct_prediction = tf.equal(predict_operation, labels)\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Train and evaluate the feature extraction model.\n",
        "#Evaluate function\n",
        "def evaluate(X, y):\n",
        "    total_acc = 0\n",
        "    num_examples = len(X)\n",
        "    total_loss = 0\n",
        "    sess = tf.compat.v1.get_default_session()\n",
        "    for offset in range(0, num_examples, batch_size):\n",
        "        end = offset + batch_size\n",
        "        X_batch = X[offset:end]\n",
        "        y_batch = y[offset:end]\n",
        "\n",
        "        loss, acc = sess.run([loss_operation, accuracy_operation], feed_dict={x: X_batch, labels: y_batch})\n",
        "        total_loss += (loss * len(X_batch))\n",
        "        total_acc += (acc * len(X_batch))\n",
        "\n",
        "    return total_loss/num_examples, total_acc/num_examples\n",
        "\n",
        "#Hyper parameters\n",
        "epochs=10\n",
        "batch_size=128\n",
        "#Train the alexnet \n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "    print(\"Start Training...\")\n",
        "    print(\"Number of epochs : {}\".format(epochs))\n",
        "    print(\"Batch size : {}\".format(batch_size))\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # training\n",
        "        X_train, y_train = shuffle(X_train, y_train)\n",
        "        for offset in range(0, X_train.shape[0], batch_size):\n",
        "            end = offset + batch_size\n",
        "            batch_x,batch_y=X_train[offset:end], y_train[offset:end]\n",
        "            sess.run(training_operation, feed_dict={x:batch_x , labels:batch_y})\n",
        "\n",
        "        val_loss, val_acc = evaluate(X_valid, y_valid)\n",
        "        print(\"Epoch\", i+1)\n",
        "        print(\"Validation Loss =\", val_loss)\n",
        "        print(\"Validation Accuracy =\", val_acc)\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "JHBG0TB2zxHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea0de9b-9743-41c8-a968-fadda8535788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training...\n",
            "Number of epochs : 10\n",
            "Batch size : 128\n",
            "Epoch 1\n",
            "Validation Loss = 0.4789389237035631\n",
            "Validation Accuracy = 0.8718439173224142\n",
            "\n",
            "Epoch 2\n",
            "Validation Loss = 0.3270055975302298\n",
            "Validation Accuracy = 0.915200204059987\n",
            "\n",
            "Epoch 3\n",
            "Validation Loss = 0.2349580618244323\n",
            "Validation Accuracy = 0.9422341238415627\n",
            "\n",
            "Epoch 4\n",
            "Validation Loss = 0.19906932551074594\n",
            "Validation Accuracy = 0.947717418919349\n",
            "\n",
            "Epoch 5\n",
            "Validation Loss = 0.17965733690305621\n",
            "Validation Accuracy = 0.9528181585113906\n",
            "\n",
            "Epoch 6\n",
            "Validation Loss = 0.15288589760999355\n",
            "Validation Accuracy = 0.9599591940983434\n",
            "\n",
            "Epoch 7\n",
            "Validation Loss = 0.13163596833278196\n",
            "Validation Accuracy = 0.9654424890393172\n",
            "\n",
            "Epoch 8\n",
            "Validation Loss = 0.13133854480368604\n",
            "Validation Accuracy = 0.9671002295332823\n",
            "\n",
            "Epoch 9\n",
            "Validation Loss = 0.12007146757936879\n",
            "Validation Accuracy = 0.969140525391381\n",
            "\n",
            "Epoch 10\n",
            "Validation Loss = 0.11379378693531253\n",
            "Validation Accuracy = 0.9693955623717431\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}