{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8E3OY6rILIgF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V3TU4_cRLIgK"
      },
      "outputs": [],
      "source": [
        "# np.load(path, allow_pickle=True)\n",
        "net_data = np.load(\"bvlc-alexnet.npy\",allow_pickle=True, encoding=\"latin1\").item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZvMPH06_LIgK"
      },
      "outputs": [],
      "source": [
        "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
        "    '''\n",
        "    From https://github.com/ethereon/caffe-tensorflow\n",
        "    '''\n",
        "    c_i = input.get_shape()[-1]\n",
        "    assert c_i % group == 0\n",
        "    assert c_o % group == 0\n",
        "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
        "    if tf.__version__ < \"1.0.0\":\n",
        "        if group == 1:\n",
        "            conv = convolve(input, kernel)\n",
        "        else:\n",
        "            input_groups = tf.split(3, group, input)\n",
        "            kernel_groups = tf.split(3, group, kernel)\n",
        "            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
        "            conv = tf.concat(3, output_groups)\n",
        "    else:\n",
        "        if group == 1:\n",
        "            conv = convolve(input, kernel)\n",
        "        else:\n",
        "            input_groups = tf.split(input, group, 3)\n",
        "            kernel_groups = tf.split(kernel, group, 3)\n",
        "            output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
        "            conv = tf.concat(output_groups, 3)\n",
        "    return tf.reshape(tf.nn.bias_add(conv, biases), [-1] + conv.get_shape().as_list()[1:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet(features, feature_extract=False):\n",
        "    \"\"\"\n",
        "    Builds an AlexNet model, loads pretrained weights\n",
        "    \"\"\"\n",
        "    # conv1\n",
        "    # conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
        "    k_h = 11\n",
        "    k_w = 11\n",
        "    c_o = 96\n",
        "    s_h = 4\n",
        "    s_w = 4\n",
        "    conv1W = tf.Variable(net_data[\"conv1\"][0])\n",
        "    conv1b = tf.Variable(net_data[\"conv1\"][1])\n",
        "    conv1_in = conv(features, conv1W, conv1b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
        "    conv1 = tf.nn.relu(conv1_in)\n",
        "\n",
        "    # lrn1\n",
        "    # lrn(2, 2e-05, 0.75, name='norm1')\n",
        "    radius = 2\n",
        "    alpha = 2e-05\n",
        "    beta = 0.75\n",
        "    bias = 1.0\n",
        "    lrn1 = tf.nn.local_response_normalization(conv1, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
        "\n",
        "    # maxpool1\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # conv2\n",
        "    # conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
        "    k_h = 5\n",
        "    k_w = 5\n",
        "    c_o = 256\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv2W = tf.Variable(net_data[\"conv2\"][0])\n",
        "    conv2b = tf.Variable(net_data[\"conv2\"][1])\n",
        "    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv2 = tf.nn.relu(conv2_in)\n",
        "\n",
        "    # lrn2\n",
        "    # lrn(2, 2e-05, 0.75, name='norm2')\n",
        "    radius = 2\n",
        "    alpha = 2e-05\n",
        "    beta = 0.75\n",
        "    bias = 1.0\n",
        "    lrn2 = tf.nn.local_response_normalization(conv2, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)\n",
        "\n",
        "    # maxpool2\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool2')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # conv3\n",
        "    # conv(3, 3, 384, 1, 1, name='conv3')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 384\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 1\n",
        "    conv3W = tf.Variable(net_data[\"conv3\"][0])\n",
        "    conv3b = tf.Variable(net_data[\"conv3\"][1])\n",
        "    conv3_in = conv(maxpool2, conv3W, conv3b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv3 = tf.nn.relu(conv3_in)\n",
        "\n",
        "    # conv4\n",
        "    # conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 384\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv4W = tf.Variable(net_data[\"conv4\"][0])\n",
        "    conv4b = tf.Variable(net_data[\"conv4\"][1])\n",
        "    conv4_in = conv(conv3, conv4W, conv4b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv4 = tf.nn.relu(conv4_in)\n",
        "\n",
        "    # conv5\n",
        "    # conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    c_o = 256\n",
        "    s_h = 1\n",
        "    s_w = 1\n",
        "    group = 2\n",
        "    conv5W = tf.Variable(net_data[\"conv5\"][0])\n",
        "    conv5b = tf.Variable(net_data[\"conv5\"][1])\n",
        "    conv5_in = conv(conv4, conv5W, conv5b, k_h, k_w, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
        "    conv5 = tf.nn.relu(conv5_in)\n",
        "\n",
        "    # maxpool5\n",
        "    # max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
        "    k_h = 3\n",
        "    k_w = 3\n",
        "    s_h = 2\n",
        "    s_w = 2\n",
        "    padding = 'VALID'\n",
        "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
        "\n",
        "    # fc6, 4096\n",
        "    fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
        "    fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
        "    flat5 = tf.reshape(maxpool5, [-1, int(np.prod(maxpool5.get_shape()[1:]))])\n",
        "    fc6 = tf.nn.relu(tf.matmul(flat5, fc6W) + fc6b)\n",
        "\n",
        "    # fc7, 4096\n",
        "    fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
        "    fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
        "    fc7 = tf.nn.relu(tf.matmul(fc6, fc7W) + fc7b)\n",
        "\n",
        "    if feature_extract:\n",
        "        return fc7\n",
        "\n",
        "    '''\n",
        "    we use this layer when  AlexNet  trained on the ImageNet database, \n",
        "    which has 1000 classes of images\n",
        "    '''\n",
        "    # fc8, 1000 \n",
        "    fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
        "    fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
        "\n",
        "    logits = tf.matmul(fc7, fc8W) + fc8b\n",
        "    probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "-HUSHH8dNb-m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **imagenet_inference**"
      ],
      "metadata": {
        "id": "b2BwInnmiu25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imread\n",
        "from caffe_classes import class_names"
      ],
      "metadata": {
        "id": "SS3CL0mTi03d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x is a placeholders for a batch of input images.\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 227, 227, 3))"
      ],
      "metadata": {
        "id": "h7W2DDRejVWz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = AlexNet(x, feature_extract=False)\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# Read Images\n",
        "im1 = (imread(\"poodle.png\")[:, :, :3] * 255).astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = (imread(\"weasel.png\")[:, :, :3] * 255).astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f__BxLnZjc0K",
        "outputId": "d04ccbf6-ff69-431a-b412-fa9e2565e11f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0\n",
            "miniature poodle: 0.389\n",
            "toy poodle: 0.223\n",
            "Bedlington terrier: 0.173\n",
            "standard poodle: 0.150\n",
            "komondor: 0.026\n",
            "\n",
            "Image 1\n",
            "weasel: 0.331\n",
            "polecat, fitch, foulmart, foumart, Mustela putorius: 0.280\n",
            "black-footed ferret, ferret, Mustela nigripes: 0.210\n",
            "mink: 0.081\n",
            "Arctic fox, white fox, Alopex lagopus: 0.027\n",
            "\n",
            "Time: 0.139 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **traffic_sign_inference**"
      ],
      "metadata": {
        "id": "hpXm2mARnA3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from imageio import imread\n",
        "from caffe_classes import class_names"
      ],
      "metadata": {
        "id": "QXPa7vfPnCmo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x is a placeholders for a batch of input images.\n",
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "#  resize the chape of the image to (227,227)\n",
        "resized = tf.image.resize(x,(227,227))"
      ],
      "metadata": {
        "id": "8US_OKawnTBh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = AlexNet(resized,feature_extract=False)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# Read Images\n",
        "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (class_names[inds[-1 - i]], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5SAv79up08i",
        "outputId": "6afbc336-04e3-42b1-c098-a9cb4b202203"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0\n",
            "screen, CRT screen: 0.058\n",
            "balance beam, beam: 0.040\n",
            "digital clock: 0.038\n",
            "parallel bars, bars: 0.022\n",
            "laptop, laptop computer: 0.022\n",
            "\n",
            "Image 1\n",
            "digital watch: 0.395\n",
            "digital clock: 0.241\n",
            "bottlecap: 0.135\n",
            "combination lock: 0.090\n",
            "stopwatch, stop watch: 0.082\n",
            "\n",
            "Time: 0.146 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **feature_extraction**"
      ],
      "metadata": {
        "id": "axwvciUubBMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio"
      ],
      "metadata": {
        "id": "fY3MRXlAcgtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imageio import imread\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n"
      ],
      "metadata": {
        "id": "7w3RDFKLa7fC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the signname csv file\n",
        "sign_names = pd.read_csv('signnames.csv')\n",
        "nb_classes = 43"
      ],
      "metadata": {
        "id": "jfMOgd_ucmpg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x is a placeholder for a batch of input images."
      ],
      "metadata": {
        "id": "aXAO8ZZieKyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.compat.v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
        "resized = tf.compat.v1.image.resize_images(x, (227, 227))"
      ],
      "metadata": {
        "id": "WKmzC9xtc0A5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: By setting `feature_extract` to `True` we return\n",
        "# the second to last layer.\n",
        "fc7 = AlexNet(resized, feature_extract=True)\n",
        "# Last fully connected layer\n",
        "shape = (fc7.get_shape().as_list()[-1], nb_classes)  \n",
        "fc8W = tf.Variable(tf.compat.v1.truncated_normal(shape=shape,  stddev = 1e-1))\n",
        "fc8b = tf.Variable(tf.zeros(nb_classes))\n",
        "logits = tf.matmul(fc7, fc8W) + fc8b\n",
        "# softmax activation function\n",
        "probs = tf.nn.softmax(logits)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "vTfeUol3c-Cl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Images\n",
        "im1 = imread(\"construction.jpg\").astype(np.float32)\n",
        "im1 = im1 - np.mean(im1)\n",
        "\n",
        "im2 = imread(\"stop.jpg\").astype(np.float32)\n",
        "im2 = im2 - np.mean(im2)\n",
        "\n",
        "# Run Inference\n",
        "t = time.time()\n",
        "output = sess.run(probs, feed_dict={x: [im1, im2]})\n",
        "\n",
        "# Print Output\n",
        "for input_im_ind in range(output.shape[0]):\n",
        "    inds = np.argsort(output)[input_im_ind, :]\n",
        "    print(\"Image\", input_im_ind)\n",
        "    for i in range(5):\n",
        "        print(\"%s: %.3f\" % (sign_names.loc[inds[-1 - i]][1], output[input_im_ind, inds[-1 - i]]))\n",
        "    print()\n",
        "\n",
        "print(\"Time: %.3f seconds\" % (time.time() - t))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWBKuCO7dkhI",
        "outputId": "83c8a774-632d-414f-f6c8-3905a5c8b1fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0\n",
            "No passing: 0.454\n",
            "Ahead only: 0.331\n",
            "Beware of ice/snow: 0.146\n",
            "Dangerous curve to the left: 0.029\n",
            "End of no passing by vechiles over 3.5 metric tons: 0.026\n",
            "\n",
            "Image 1\n",
            "Speed limit (60km/h): 0.739\n",
            "Roundabout mandatory: 0.232\n",
            "Speed limit (30km/h): 0.017\n",
            "Go straight or right: 0.004\n",
            "No passing for vechiles over 3.5 metric tons: 0.004\n",
            "\n",
            "Time: 0.148 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "alexnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}